#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Community Data Scraper Module
Contains all the web scraping logic from the original script
Modified to support incremental updates
"""

import requests
from urllib.parse import urljoin, unquote
from bs4 import BeautifulSoup
import time
import re
from pathlib import Path
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import threading
from typing import Callable, Optional, Dict, List, Tuple
import os
from datetime import datetime
import difflib


class CommunityDataScraper:
    def __init__(self, progress_callback: Optional[Callable] = None, status_callback: Optional[Callable] = None, output_folder: Optional[str] = None):
        self.base_url = "https://group.lifego.tw/"  # ç›®æ¨™ç¶²ç«™çš„åŸºç¤URL  
        # è¨­å®šHTTPè«‹æ±‚æ¨™é ­ï¼Œæ¨¡æ“¬ç€è¦½å™¨è¡Œç‚º
        self.headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/114.0.0.0 Safari/537.36"
            )
        }
        self.session = self._build_session()  # å»ºç«‹æ”¯æ´é‡è©¦çš„Sessionç‰©ä»¶
        self.progress_callback = progress_callback  # å„²å­˜é€²åº¦å›èª¿å‡½å¼
        self.status_callback = status_callback  # å„²å­˜ç‹€æ…‹å›èª¿å‡½å¼
        self.should_stop = False  # æ§åˆ¶çˆ¬å–æ˜¯å¦åœæ­¢çš„æ¨™èªŒ
        self.output_folder = output_folder or os.getcwd()  # è¨­å®šè¼¸å‡ºè³‡æ–™å¤¾ï¼Œé è¨­ç‚ºç•¶å‰ç›®éŒ„
        
    def _build_session(self) -> requests.Session:
        """å»ºç«‹ä¸€æ”¯æ”¯æŒé‡è©¦çš„ Session"""
        session = requests.Session()
        retries = Retry(
            total=5,                   # æœ€å¤šé‡è©¦ 5 æ¬¡ (åŒ…å«ä¸‹é¢å„é …)
            connect=5,                 # é€£ç·šéŒ¯èª¤æ™‚æœ€å¤šå†é‡è©¦ 5 æ¬¡
            read=5,                    # è®€å–é€¾æ™‚æ™‚æœ€å¤šå†é‡è©¦ 5 æ¬¡
            backoff_factor=1,          # é‡è©¦é–“éš”ï¼š1s, 2s, 4s, 8s, â€¦
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS", "POST"],  # é‡å°é€™äº›æ–¹æ³•å•Ÿç”¨é‡è©¦
            raise_on_status=False      # ä¸å› ç‚ºç‹€æ…‹ç¢¼è€Œæ‹‹å‡ºç•°å¸¸
        )
           
        adapter = HTTPAdapter(max_retries=retries)  # å»ºç«‹HTTPé©é…å™¨
        session.mount('https://', adapter)  # ç‚ºHTTPSè«‹æ±‚æ›è¼‰é©é…å™¨
        session.mount('http://', adapter)  # ç‚ºHTTPè«‹æ±‚æ›è¼‰é©é…å™¨
        return session  # è¿”å›é…ç½®å¥½çš„Session
    
    def _update_status(self, message: str):
        """
        æ›´æ–°ç‹€æ…‹è¨Šæ¯
        
        Args:
            message: è¦é¡¯ç¤ºçš„ç‹€æ…‹è¨Šæ¯
        """
        if self.status_callback:  # å¦‚æœæœ‰è¨­å®šç‹€æ…‹å›èª¿å‡½å¼
            self.status_callback(message)  # å‘¼å«å›èª¿å‡½å¼æ›´æ–°ç‹€æ…‹
    
    def _update_progress(self, current: int, total: int):
        """
        æ›´æ–°é€²åº¦
        
        Args:
            current: ç•¶å‰é€²åº¦
            total: ç¸½é€²åº¦
        """
        if self.progress_callback:  # å¦‚æœæœ‰è¨­å®šé€²åº¦å›èª¿å‡½å¼
            self.progress_callback(current, total)  # å‘¼å«å›èª¿å‡½å¼æ›´æ–°é€²åº¦
    
    def stop_scraping(self):
        """åœæ­¢çˆ¬å–"""
        self.should_stop = True  # è¨­å®šåœæ­¢æ¨™èªŒç‚ºTrue
    
    def create_city_folder(self, city_name: str, city_count: Optional[str] = None):
        """
        å»ºç«‹åŸå¸‚è³‡æ–™å¤¾
        
        Args:
            city_name: åŸå¸‚åç¨±
            city_count: åŸå¸‚è³‡æ–™ç¸½ç­†æ•¸ï¼ˆå¯é¸ï¼‰
            
        Returns:
            åŸå¸‚è³‡æ–™å¤¾çš„Pathç‰©ä»¶
        """
        # å¦‚æœæœ‰æä¾›ç­†æ•¸ï¼Œå°‡ç­†æ•¸åŠ åˆ°è³‡æ–™å¤¾åç¨±ä¸­
        # å»ºç«‹åŸºç¤è³‡æ–™å¤¾åç¨±
        if city_count:
            city_data_name = f"{city_name}({city_count}ç­†è³‡æ–™)"
        else:
            city_data_name = city_name
        
        # ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸ
        today_str = datetime.now().strftime("%Y_%m_%d")
        today_folder_name = f"{city_data_name}_{today_str}"
        
        # ç¢ºå®šå·¥ä½œç›®éŒ„
        base_dir = Path(self.output_folder)
        base_dir.mkdir(parents=True, exist_ok=True)
        
        today_folder_path = base_dir / today_folder_name
        
        # å»ºç«‹æ­£è¦è¡¨é”å¼æ¨¡å¼
        escaped_city_name = re.escape(city_data_name)
        pattern = re.compile(rf"^{escaped_city_name}_(\d{{4}}_\d{{2}}_\d{{2}})$")
        
        # å°‹æ‰¾ä¸¦åˆ†æèˆŠè³‡æ–™å¤¾
        old_folders = []
        try:
            for entry in base_dir.iterdir():
                if entry.is_dir() and pattern.match(entry.name):
                    if entry.name != today_folder_name:
                        date_match = pattern.match(entry.name)
                        if date_match:
                            date_str = date_match.group(1)
                            try:
                                # è½‰æ›ç‚ºæ—¥æœŸç‰©ä»¶ä»¥ä¾¿æ¯”è¼ƒ
                                folder_date = datetime.strptime(date_str, "%Y_%m_%d")
                                old_folders.append((entry, date_str, folder_date))
                            except ValueError:
                                self._update_status(f"âš ï¸ ç„¡æ³•è§£ææ—¥æœŸ: {date_str}")
        except (OSError, PermissionError) as e:
            self._update_status(f"âš ï¸ è®€å–ç›®éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        old_folders.sort(key=lambda x: x[2], reverse=True)
        
        # è™•ç†ä»Šå¤©çš„è³‡æ–™å¤¾
        if today_folder_path.exists():
            self._update_status(f"ğŸ“‚ ä»Šå¤©çš„è³‡æ–™å¤¾ {today_folder_name} å·²å­˜åœ¨ï¼Œç¹¼çºŒä½¿ç”¨")
        else:
            if old_folders:
                # å°‡æœ€æ–°çš„èˆŠè³‡æ–™å¤¾æ”¹åç‚ºä»Šå¤©çš„
                old_folder_path, old_date_str, old_date = old_folders[0]
                try:
                    old_folder_path.rename(today_folder_path)
                    self._update_status(f"ğŸ“ å·²å°‡è³‡æ–™å¤¾ {old_folder_path.name} æ”¹åç‚º {today_folder_name}")
                except (OSError, PermissionError) as e:
                    self._update_status(f"âŒ æ”¹åè³‡æ–™å¤¾å¤±æ•—: {e}")
                    today_folder_path.mkdir(parents=True, exist_ok=True)
                    self._update_status(f"âœ… å·²å»ºç«‹æ–°è³‡æ–™å¤¾: {today_folder_name}")
            else:
                # æ²’æœ‰èˆŠè³‡æ–™å¤¾ï¼Œå»ºç«‹æ–°çš„
                try:
                    today_folder_path.mkdir(parents=True, exist_ok=True)
                    self._update_status(f"âœ… å·²å»ºç«‹è³‡æ–™å¤¾: {today_folder_name}")
                except (OSError, PermissionError) as e:
                    self._update_status(f"âŒ å»ºç«‹è³‡æ–™å¤¾å¤±æ•—: {e}")
                    return base_dir
        
        return today_folder_path
 
    
    def separate_name(self, text: str) -> Tuple[str, str]:
        """
        åˆ†é›¢åç¨±å’Œæ•¸é‡
        ä¾‹å¦‚ï¼šå°‡ "å°åŒ—å¸‚(1000)" åˆ†é›¢ç‚º "å°åŒ—å¸‚" å’Œ "1000"
        
        Args:
            text: åŒ…å«åç¨±å’Œæ•¸é‡çš„æ–‡å­—
            
        Returns:
            (åç¨±, æ•¸é‡) çš„å…ƒçµ„
        """
        name_part, sep, num_part = text.partition('(')  # ä»¥'('ç‚ºåˆ†éš”ç¬¦åˆ†å‰²å­—ä¸²
        name = name_part.strip()  # å»é™¤åç¨±å‰å¾Œç©ºç™½
        count = num_part.rstrip(')').strip()  # å»é™¤æ•¸é‡éƒ¨åˆ†çš„')'å’Œç©ºç™½
        return name, count  # è¿”å›åç¨±å’Œæ•¸é‡
    
    def get_city_data(self) -> List[Dict]:
        """
        ç²å–æ‰€æœ‰åŸå¸‚è³‡æ–™
        
        Returns:
            åŸå¸‚è³‡æ–™åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ åŒ…å«åŸå¸‚åç¨±ã€æ•¸é‡ã€å€åŸŸåˆ—è¡¨ç­‰è³‡è¨Š
        """
        try:
            self._update_status("æ­£åœ¨ç²å–åŸå¸‚åˆ—è¡¨...")  # æ›´æ–°ç‹€æ…‹
            response = self.session.get(self.base_url, headers=self.headers, timeout=10)  # ç™¼é€GETè«‹æ±‚
            response.raise_for_status()  # å¦‚æœè«‹æ±‚å¤±æ•—å‰‡æ‹‹å‡ºç•°å¸¸
            soup = BeautifulSoup(response.text, "html.parser")  # è§£æHTML
            city_tree = soup.find_all('li', {'class': 'treeview'})  # æ‰¾åˆ°æ‰€æœ‰åŸå¸‚ç¯€é»
            
            cities = []  # åˆå§‹åŒ–åŸå¸‚åˆ—è¡¨
            for tree in city_tree:  # éæ­·æ¯å€‹åŸå¸‚ç¯€é»
                span = tree.find('span')  # æ‰¾åˆ°åŸå¸‚åç¨±çš„spanæ¨™ç±¤
                if not span:  # å¦‚æœæ²’æœ‰æ‰¾åˆ°spanæ¨™ç±¤
                    continue  # è·³éé€™å€‹ç¯€é»
                
                city_text = span.get_text(strip=True)  # ç²å–åŸå¸‚æ–‡å­—ä¸¦å»é™¤ç©ºç™½
                city_name, city_count = self.separate_name(city_text)  # åˆ†é›¢åŸå¸‚åç¨±å’Œæ•¸é‡
                
                # ç²å–è©²åŸå¸‚çš„å€åŸŸåˆ—è¡¨
                districts = []  # åˆå§‹åŒ–å€åŸŸåˆ—è¡¨
                for city in tree.find_all('ul', {'class': 'treeview-menu'}):  # æ‰¾åˆ°å€åŸŸé¸å–®
                    for dis in city.find_all('li'):  # éæ­·æ¯å€‹å€åŸŸ
                        a_tag = dis.find('a')  # æ‰¾åˆ°é€£çµæ¨™ç±¤
                        if not a_tag:  # å¦‚æœæ²’æœ‰æ‰¾åˆ°é€£çµ
                            continue  # è·³éé€™å€‹å€åŸŸ
                        a_text = a_tag.get_text(strip=True)  # ç²å–é€£çµæ–‡å­—
                        if a_text.startswith('å…¨éƒ¨'):  # å¦‚æœæ˜¯"å…¨éƒ¨"é¸é …
                            continue  # è·³éï¼Œä¸åŠ å…¥å€åŸŸåˆ—è¡¨
                        district_name, district_count = self.separate_name(a_text)  # åˆ†é›¢å€åŸŸåç¨±å’Œæ•¸é‡
                        districts.append({  # å°‡å€åŸŸè³‡è¨ŠåŠ å…¥åˆ—è¡¨
                            'name': district_name,
                            'count': district_count,
                            'url': urljoin(self.base_url, unquote(a_tag['href']))  # åˆä½µå®Œæ•´URL
                        })
                
                # ç²å–åŸå¸‚å…¨éƒ¨è³‡æ–™çš„URL
                city_all_url = None  # åˆå§‹åŒ–åŸå¸‚å…¨éƒ¨è³‡æ–™URL
                for city in tree.find_all('ul', {'class': 'treeview-menu'}):  # æ‰¾åˆ°é¸å–®
                    a_tag = city.find('a')  # æ‰¾åˆ°ç¬¬ä¸€å€‹é€£çµï¼ˆé€šå¸¸æ˜¯"å…¨éƒ¨"é¸é …ï¼‰
                    if a_tag:  # å¦‚æœæ‰¾åˆ°é€£çµ
                        city_all_url = urljoin(self.base_url, unquote(a_tag['href']))  # åˆä½µå®Œæ•´URL
                        break  # æ‰¾åˆ°ç¬¬ä¸€å€‹å°±çµæŸ
                
                cities.append({  # å°‡åŸå¸‚è³‡è¨ŠåŠ å…¥åˆ—è¡¨
                    'name': city_name,
                    'count': city_count,
                    'districts': districts,
                    'all_url': city_all_url
                })
            
            self._update_status(f"æˆåŠŸç²å– {len(cities)} å€‹åŸå¸‚è³‡æ–™")  # æ›´æ–°ç‹€æ…‹
            return cities  # è¿”å›åŸå¸‚åˆ—è¡¨
            
        except Exception as e:  # æ•æ‰ä»»ä½•ç•°å¸¸
            self._update_status(f"ç²å–åŸå¸‚è³‡æ–™å¤±æ•—: {str(e)}")  # æ›´æ–°éŒ¯èª¤ç‹€æ…‹
            return []  # è¿”å›ç©ºåˆ—è¡¨

    def parse_existing_communities(self, file_path: Path) -> Dict[str, Dict[str, str]]:
        """
        è§£æç¾æœ‰æª”æ¡ˆä¸­çš„ç¤¾å€è³‡æ–™
        
        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            
        Returns:
            å­—å…¸ï¼Œkeyç‚ºç¤¾å€åç¨±ï¼Œvalueç‚ºåŒ…å«é›»è©±å’Œåœ°å€çš„å­—å…¸
        """
        communities = {}
        
        if not file_path.exists():
            return communities
        
        try:
            with file_path.open('r', encoding='utf-8') as f:
                content = f.read()
            
            # ä»¥ç©ºè¡Œåˆ†å‰²æ¯å€‹ç¤¾å€çš„è³‡æ–™
            blocks = re.split(r'\n\s*\n', content.strip())
            
            for block in blocks:
                if not block.strip():
                    continue
                
                lines = [line.strip() for line in block.split('\n') if line.strip()]
                if not lines:
                    continue
                
                community_name = lines[0]
                phone = ''
                address = ''
                
                # è§£æé›»è©±å’Œåœ°å€
                for line in lines[1:]:
                    if ':' in line or 'ï¼š' in line:
                        separator = ':' if ':' in line else 'ï¼š'
                        parts = line.split(separator, 1)
                        if len(parts) == 2:
                            key = parts[0].strip()
                            value = parts[1].strip()
                            
                            if key == 'é›»è©±':
                                phone = value
                            elif key == 'åœ°å€':
                                address = value
                
                if community_name:
                    communities[community_name] = {
                        'phone': phone,
                        'address': address
                    }
        
        except Exception as e:
            self._update_status(f"è§£æç¾æœ‰æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        return communities

    def scrape_new_communities_from_web(self, url: str) -> List[Dict[str, str]]:
        """
        å¾ç¶²ç«™çˆ¬å–æ‰€æœ‰ç¤¾å€è³‡æ–™
        
        Args:
            url: è¦çˆ¬å–çš„URL
            
        Returns:
            ç¤¾å€è³‡æ–™åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ åŒ…å« name, phone, address
        """
        all_communities = []
        
        try:
            page = 1
            
            while not self.should_stop:
                self._update_status(f"æ­£åœ¨çˆ¬å–ç¬¬ {page} é ...")
                
                response = self.session.get(url, headers=self.headers, timeout=10)
                response.raise_for_status()
                soup = BeautifulSoup(response.text, "html.parser")
                
                div_tags = soup.find_all('div', {'class': 'product-info'})
                if not div_tags:
                    break
                    
                for div_tag in div_tags:
                    if self.should_stop:
                        break
                        
                    a_title = div_tag.find('a')
                    if not a_title:
                        continue
                        
                    title = a_title.text.strip().replace('\xa0', '')
                    if title:
                        phone = address = ""
                        spans = div_tag.find('span')
                        if spans:
                            for label in spans.find_all('label'):
                                label_name = label.get_text(strip=True).replace('\xa0', '')
                                label_text = label.next_sibling
                                if not label_text:
                                    continue
                                value = label_text.strip().replace('\xa0', '')
                                if label_name == "é›»è©±":
                                    phone = value
                                elif label_name == "åœ°å€":
                                    address = value
                        
                        all_communities.append({
                            'name': title,
                            'phone': phone,
                            'address': address
                        })
                
                # å°‹æ‰¾ä¸‹ä¸€é é€£çµ
                a_tag = soup.find('a', class_='btn btn-primary', string=re.compile(r'ä¸‹ä¸€é '))
                href = a_tag and a_tag.get('href')
                if not href:
                    break
                
                url = urljoin(self.base_url, unquote(href))
                page += 1
                time.sleep(2)  # ç­‰å¾…2ç§’ï¼Œé¿å…è«‹æ±‚éæ–¼é »ç¹
        
        except Exception as e:
            self._update_status(f"çˆ¬å–ç¶²ç«™è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        return all_communities
    
    def compare_and_log_updates(self, old_file_path: Path, new_file_path: Path) -> List[Dict[str, str]]:
        """
        æ¯”å°èˆŠæª”æ¡ˆå’Œæ–°æª”æ¡ˆçš„å·®ç•°ï¼Œè¿”å›æ–°å¢çš„å®Œæ•´ç¤¾å€è³‡è¨Š
        
        Args:
            old_file_path: èˆŠæª”æ¡ˆè·¯å¾‘
            new_file_path: æ–°æª”æ¡ˆè·¯å¾‘
            
        Returns:
            æ–°å¢ç¤¾å€è³‡è¨Šçš„åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ åŒ…å« {'name': '', 'phone': '', 'address': ''}
        """
        try:
            # è§£æèˆŠæª”æ¡ˆä¸­çš„ç¤¾å€è³‡è¨Š
            old_communities = []
            if old_file_path.exists():
                with old_file_path.open('r', encoding='utf-8') as f:
                    old_content = f.read()
                
                # ä»¥ç©ºè¡Œåˆ†å‰²æ¯å€‹ç¤¾å€çš„è³‡æ–™
                old_blocks = re.split(r'\n\s*\n', old_content.strip())
                
                for block in old_blocks:
                    if not block.strip():
                        continue
                    
                    lines = [line.strip() for line in block.split('\n') if line.strip()]
                    if not lines:
                        continue
                    
                    community = {
                        'name': lines[0] if lines else '',
                        'phone': '',
                        'address': ''
                    }
                    
                    # è§£æé›»è©±å’Œåœ°å€
                    for line in lines[1:]:
                        if ':' in line or 'ï¼š' in line:
                            separator = ':' if ':' in line else 'ï¼š'
                            parts = line.split(separator, 1)
                            if len(parts) == 2:
                                key = parts[0].strip()
                                value = parts[1].strip()
                                
                                if key == 'é›»è©±':
                                    community['phone'] = value
                                elif key == 'åœ°å€':
                                    community['address'] = value
                    
                    if community['name']:
                        old_communities.append(community)
            
            # è§£ææ–°æª”æ¡ˆä¸­çš„ç¤¾å€è³‡è¨Š
            new_communities = []
            with new_file_path.open('r', encoding='utf-8') as f:
                new_content = f.read()
            
            # ä»¥ç©ºè¡Œåˆ†å‰²æ¯å€‹ç¤¾å€çš„è³‡æ–™
            new_blocks = re.split(r'\n\s*\n', new_content.strip())
            
            for block in new_blocks:
                if not block.strip():
                    continue
                
                lines = [line.strip() for line in block.split('\n') if line.strip()]
                if not lines:
                    continue
                
                community = {
                    'name': lines[0] if lines else '',
                    'phone': '',
                    'address': ''
                }
                
                # è§£æé›»è©±å’Œåœ°å€
                for line in lines[1:]:
                    if ':' in line or 'ï¼š' in line:
                        separator = ':' if ':' in line else 'ï¼š'
                        parts = line.split(separator, 1)
                        if len(parts) == 2:
                            key = parts[0].strip()
                            value = parts[1].strip()
                            
                            if key == 'é›»è©±':
                                community['phone'] = value
                            elif key == 'åœ°å€':
                                community['address'] = value
                
                if community['name']:
                    new_communities.append(community)
            
            # å‰µå»ºèˆŠç¤¾å€åç¨±çš„é›†åˆï¼Œç”¨æ–¼å¿«é€ŸæŸ¥æ‰¾
            old_community_names = {community['name'] for community in old_communities}
            
            # æ‰¾å‡ºæ–°å¢çš„ç¤¾å€
            new_items = []
            for community in new_communities:
                if community['name'] not in old_community_names:
                    new_items.append(community)
            
            return new_items
            
        except Exception as e:
            self._update_status(f"æ¯”å°æª”æ¡ˆå·®ç•°æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    def create_update_log(self, updates: Dict[str, List[Dict[str, str]]]):
        """
        å»ºç«‹å¢å¼·ç‰ˆæ›´æ–°æ—¥èªŒ - åŒ…å«å®Œæ•´çš„ç¤¾å€è³‡è¨Š
        
        Args:
            updates: æ›´æ–°é …ç›®å­—å…¸ï¼Œkeyç‚ºæª”æ¡ˆåç¨±ï¼Œvalueç‚ºæ–°å¢ç¤¾å€è³‡è¨Šåˆ—è¡¨
        """
        try:
            if not any(updates.values()):
                self._update_status("æ²’æœ‰æ–°å¢é …ç›®ï¼Œä¸å»ºç«‹æ›´æ–°æ—¥èªŒ")
                return
            
            # å»ºç«‹æ›´æ–°æ—¥èªŒè³‡æ–™å¤¾
            log_folder = Path(self.output_folder) / "è³‡æ–™æ›´æ–°æ—¥èªŒ"
            log_folder.mkdir(parents=True, exist_ok=True)
            
            # å»ºç«‹æ›´æ–°æ—¥èªŒæª”æ¡ˆ (ä½¿ç”¨æ—¥æœŸå‘½å)
            date_str = datetime.now().strftime("%Y-%m-%d")
            log_file_path = log_folder / f"{date_str}è³‡æ–™æ›´æ–°æ—¥èªŒ.txt"
            
            with log_file_path.open('a', encoding='utf-8') as f:
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                f.write(f"è³‡æ–™æ›´æ–°æ—¥èªŒ - {timestamp}\n")
                f.write("=" * 60 + "\n\n")
                
                total_new_items = 0
                for file_name, new_communities in updates.items():
                    if new_communities:
                        f.write(f"æª”æ¡ˆ: {file_name}\n")
                        f.write(f"æ–°å¢é …ç›®æ•¸é‡: {len(new_communities)}\n")
                        f.write("-" * 40 + "\n")
                        
                        for community in new_communities:
                            # ç¤¾å€åç¨±
                            f.write(f"+ {community['name']}\n")
                            
                            # é›»è©±è³‡è¨Š
                            phone = community.get('phone', '') or 'æœªæä¾›'
                            f.write(f"  ğŸ“ é›»è©±: {phone}\n")
                            
                            # åœ°å€è³‡è¨Š
                            address = community.get('address', '') or 'æœªæä¾›'
                            f.write(f"  ğŸ“ åœ°å€: {address}\n")
                            
                            f.write("\n")  # æ¯å€‹ç¤¾å€å¾Œæ·»åŠ ç©ºè¡Œ
                        
                        f.write("\n")
                        total_new_items += len(new_communities)
                
                f.write(f"ç¸½è¨ˆæ–°å¢é …ç›®: {total_new_items} ç­†\n")
                f.write("=" * 60 + "\n")
            
            self._update_status(f"å·²å»ºç«‹æ›´æ–°æ—¥èªŒ: {log_file_path}")
            
        except Exception as e:
            self._update_status(f"å»ºç«‹æ›´æ–°æ—¥èªŒæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}") 

    
    def find_data(self, url: str, city_name: str, district_name: Optional[str], 
                  count: str, do_dis: str, city_count: Optional[str] = None) -> bool:
        """
        çˆ¬å–ç¤¾å€è³‡æ–™ - ä¿®æ”¹ç‚ºå¢é‡æ›´æ–°æ¨¡å¼ï¼Œåœ¨æª”æ¡ˆå…§ç›´æ¥é¡¯ç¤ºæ›´æ–°æ—¥èªŒ
        
        Args:
            url: è¦çˆ¬å–çš„URL
            city_name: åŸå¸‚åç¨±
            district_name: å€åŸŸåç¨±ï¼ˆå¯é¸ï¼‰
            count: è³‡æ–™æ•¸é‡
            do_dis: æ˜¯å¦åˆ†å€ï¼ˆ"æ˜¯"æˆ–"å¦"ï¼‰
            city_count: åŸå¸‚ç¸½ç­†æ•¸ï¼ˆå¯é¸ï¼‰

        Returns:
            Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±æ•—
        """
        try:
            city_folder = self.create_city_folder(city_name, city_count)
            
            today_str = datetime.now().strftime("%Y_%m_%d")
            # æ ¹æ“šæ˜¯å¦åˆ†å€è¨­å®šæª”æ¡ˆåç¨±
            if do_dis == "å¦":
                file_name = f"{city_name}å…¨éƒ¨ç¤¾å€è³‡æ–™(å…±æœ‰{count}ç­†)_{today_str}.txt"
            elif do_dis == "æ˜¯":
                file_name = f"{city_name}{district_name}ç¤¾å€è³‡æ–™(å…±æœ‰{count}ç­†)_{today_str}.txt"
            
            file_path = city_folder / file_name
            
            self._update_status(f"æ­£åœ¨çˆ¬å–: {file_name}")
            self._update_status(f"è¼¸å‡ºè·¯å¾‘: {file_path}")
            
            # 1. è§£æç¾æœ‰æª”æ¡ˆä¸­çš„æ‰€æœ‰ç¤¾å€è³‡æ–™ï¼ˆåŒ…å«èˆŠè³‡æ–™å’Œä¹‹å‰æ–°å¢çš„ï¼‰
            existing_communities = {}
            if file_path.exists():
                with file_path.open('r', encoding='utf-8') as f:
                    content = f.read()
                existing_communities = self.parse_existing_communities_from_content(content)
                self._update_status(f"ç¾æœ‰æª”æ¡ˆä¸­å·²æœ‰ {len(existing_communities)} ç­†ç¤¾å€è³‡æ–™")
            
            # 2. å¾ç¶²ç«™çˆ¬å–æ‰€æœ‰ç¤¾å€è³‡æ–™
            self._update_status("é–‹å§‹å¾ç¶²ç«™çˆ¬å–æœ€æ–°è³‡æ–™...")
            all_web_communities = self.scrape_new_communities_from_web(url)
            
            if self.should_stop:
                return False
            
            self._update_status(f"å¾ç¶²ç«™çˆ¬å–åˆ° {len(all_web_communities)} ç­†ç¤¾å€è³‡æ–™")
            
            # 3. æ‰¾å‡ºæ–°å¢çš„ç¤¾å€
            new_communities = []
            for community in all_web_communities:
                if community['name'] not in existing_communities:
                    new_communities.append(community)
            
            self._update_status(f"ç™¼ç¾ {len(new_communities)} ç­†æ–°å¢ç¤¾å€è³‡æ–™")
            
            # 4. é‡æ–°çµ„ç¹”æ‰€æœ‰è³‡æ–™ï¼šå°‡æ‰€æœ‰ç¾æœ‰è³‡æ–™ï¼ˆåŒ…æ‹¬ä¹‹å‰æ–°å¢çš„ï¼‰æ•´åˆç‚ºæ¨™æº–æ ¼å¼
            with file_path.open(mode="w", encoding="utf-8") as file:
                # å¯«å…¥æ‰€æœ‰ç¾æœ‰ç¤¾å€ï¼ˆæ¨™æº–æ ¼å¼ï¼‰
                all_existing_from_web = []
                for community in all_web_communities:
                    if community['name'] in existing_communities:
                        all_existing_from_web.append(community)
                
                # å¯«å…¥ç¾æœ‰ç¤¾å€è³‡æ–™ï¼ˆæ¨™æº–æ ¼å¼ï¼‰
                for community in all_existing_from_web:
                    file.write(f"{community['name']}\n")
                    file.write(f"é›»è©±: {community['phone']}\n")
                    file.write(f"åœ°å€: {community['address']}\n")
                    file.write("\n")
                
                # å¦‚æœæœ‰æ–°å¢è³‡æ–™ï¼Œæ·»åŠ æ›´æ–°æ—¥èªŒæ ¼å¼
                if new_communities:
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    file.write("============================================================\n")
                    file.write(f"è³‡æ–™æ›´æ–°æ—¥èªŒ - {timestamp}\n")
                    file.write("============================================================\n")
                    file.write(f"æª”æ¡ˆ: {file_name}\n")
                    file.write(f"æ–°å¢é …ç›®æ•¸é‡: {len(new_communities)}\n")
                    file.write("----------------------------------------\n")
                    
                    for community in new_communities:
                        file.write(f"+ {community['name']}\n")
                        phone = community.get('phone', '') or 'æœªæä¾›'
                        file.write(f"  ğŸ“ é›»è©±: {phone}\n")
                        address = community.get('address', '') or 'æœªæä¾›'
                        file.write(f"  ğŸ“ åœ°å€: {address}\n")
                        file.write("\n")
                    
                    file.write(f"ç¸½è¨ˆæ–°å¢é …ç›®: {len(new_communities)} ç­†\n")
                    
                    self._update_status(f"âœ… å·²å°‡ {len(new_communities)} ç­†æ–°å¢è³‡æ–™åŠ å…¥æª”æ¡ˆ")
                else:
                    self._update_status("ğŸ“‹ æ²’æœ‰ç™¼ç¾æ–°å¢è³‡æ–™")
            
            # è¨˜éŒ„æ›´æ–°è³‡è¨Šç”¨æ–¼å¤–éƒ¨æ—¥èªŒï¼ˆå¦‚æœéœ€è¦çš„è©±ï¼‰
            if hasattr(self, '_update_log_data'):
                self._update_log_data[file_name] = new_communities
            else:
                self._update_log_data = {file_name: new_communities}
            
            if not self.should_stop:
                self._update_status(f"å®Œæˆè™•ç†: {file_name}")
                return True
            else:
                self._update_status("è™•ç†å·²åœæ­¢")
                return False
                
        except Exception as e:
            self._update_status(f"è™•ç†å¤±æ•—: {str(e)}")
            return False

    def parse_existing_communities_from_content(self, content: str) -> Dict[str, Dict[str, str]]:
        """
        å¾å…§å®¹å­—ä¸²è§£æç¾æœ‰çš„ç¤¾å€è³‡æ–™ï¼ˆåŒ…å«èˆŠè³‡æ–™å’Œä¹‹å‰æ–°å¢çš„è³‡æ–™ï¼‰
        
        Args:
            content: æª”æ¡ˆå…§å®¹å­—ä¸²
            
        Returns:
            å­—å…¸ï¼Œkeyç‚ºç¤¾å€åç¨±ï¼Œvalueç‚ºåŒ…å«é›»è©±å’Œåœ°å€çš„å­—å…¸
        """
        communities = {}
        
        if not content.strip():
            return communities
        
        try:
            # å…ˆè™•ç†èˆŠè³‡æ–™éƒ¨åˆ†ï¼ˆåˆ†éš”ç·šä¹‹å‰çš„å…§å®¹ï¼‰
            separator_pattern = r'={60,}'
            parts = re.split(separator_pattern, content)
            
            if parts:
                # è§£æåˆ†éš”ç·šä¹‹å‰çš„èˆŠè³‡æ–™
                old_data_content = parts[0].strip()
                if old_data_content:
                    old_communities = self._parse_community_blocks(old_data_content)
                    communities.update(old_communities)
                
                # å¦‚æœæœ‰æ›´æ–°æ—¥èªŒéƒ¨åˆ†ï¼Œè§£æå…¶ä¸­çš„æ–°å¢è³‡æ–™
                if len(parts) > 1:
                    log_content = ''.join(parts[1:])  # åˆä½µæ‰€æœ‰æ›´æ–°æ—¥èªŒéƒ¨åˆ†
                    new_communities = self._parse_update_log_communities(log_content)
                    communities.update(new_communities)
            else:
                # æ²’æœ‰åˆ†éš”ç·šï¼Œæ•´å€‹å…§å®¹éƒ½æ˜¯èˆŠè³‡æ–™
                all_communities = self._parse_community_blocks(content)
                communities.update(all_communities)
        
        except Exception as e:
            self._update_status(f"è§£æç¾æœ‰å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        return communities

    def _parse_community_blocks(self, content: str) -> Dict[str, Dict[str, str]]:
        """
        è§£ææ¨™æº–æ ¼å¼çš„ç¤¾å€è³‡æ–™å€å¡Š
        
        Args:
            content: è¦è§£æçš„å…§å®¹
            
        Returns:
            è§£æå‡ºçš„ç¤¾å€è³‡æ–™å­—å…¸
        """
        communities = {}
        
        # ä»¥ç©ºè¡Œåˆ†å‰²æ¯å€‹ç¤¾å€çš„è³‡æ–™
        blocks = re.split(r'\n\s*\n', content.strip())
        
        for block in blocks:
            if not block.strip():
                continue
            
            lines = [line.strip() for line in block.split('\n') if line.strip()]
            if not lines:
                continue
            
            community_name = lines[0]
            phone = ''
            address = ''
            
            # è§£æé›»è©±å’Œåœ°å€
            for line in lines[1:]:
                if ':' in line or 'ï¼š' in line:
                    separator = ':' if ':' in line else 'ï¼š'
                    parts = line.split(separator, 1)
                    if len(parts) == 2:
                        key = parts[0].strip()
                        value = parts[1].strip()
                        
                        if key == 'é›»è©±':
                            phone = value
                        elif key == 'åœ°å€':
                            address = value
            
            if community_name:
                communities[community_name] = {
                    'phone': phone,
                    'address': address
                }
        
        return communities

    def _parse_update_log_communities(self, log_content: str) -> Dict[str, Dict[str, str]]:
        """
        è§£ææ›´æ–°æ—¥èªŒä¸­çš„ç¤¾å€è³‡æ–™
        
        Args:
            log_content: æ›´æ–°æ—¥èªŒå…§å®¹
            
        Returns:
            è§£æå‡ºçš„ç¤¾å€è³‡æ–™å­—å…¸
        """
        communities = {}
        
        try:
            # å°‹æ‰¾æ‰€æœ‰ä»¥ "+ " é–‹é ­çš„ç¤¾å€åç¨±è¡Œ
            lines = log_content.split('\n')
            i = 0
            
            while i < len(lines):
                line = lines[i].strip()
                
                # æ‰¾åˆ°ç¤¾å€åç¨±è¡Œï¼ˆä»¥ "+ " é–‹é ­ï¼‰
                if line.startswith('+ '):
                    community_name = line[2:].strip()  # å»é™¤ "+ " å‰ç¶´
                    phone = ''
                    address = ''
                    
                    # æŸ¥çœ‹æ¥ä¸‹ä¾†çš„å¹¾è¡Œï¼Œå°‹æ‰¾é›»è©±å’Œåœ°å€
                    j = i + 1
                    while j < len(lines) and j < i + 5:  # æœ€å¤šæª¢æŸ¥å¾Œé¢5è¡Œ
                        next_line = lines[j].strip()
                        
                        # å¦‚æœé‡åˆ°ä¸‹ä¸€å€‹ç¤¾å€æˆ–å…¶ä»–åˆ†éš”å…§å®¹ï¼Œåœæ­¢
                        if (next_line.startswith('+ ') or 
                            next_line.startswith('ç¸½è¨ˆæ–°å¢é …ç›®') or
                            next_line.startswith('============')):
                            break
                        
                        # è§£æé›»è©±å’Œåœ°å€
                        if 'ğŸ“ é›»è©±:' in next_line:
                            phone = next_line.split('ğŸ“ é›»è©±:', 1)[1].strip()
                        elif 'ğŸ“ åœ°å€:' in next_line:
                            address = next_line.split('ğŸ“ åœ°å€:', 1)[1].strip()
                        
                        j += 1
                    
                    if community_name:
                        communities[community_name] = {
                            'phone': phone,
                            'address': address
                        }
                    
                    i = j  # è·³åˆ°è™•ç†å®Œçš„ä½ç½®
                else:
                    i += 1
        
        except Exception as e:
            self._update_status(f"è§£ææ›´æ–°æ—¥èªŒæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        return communities
    
    def scrape_all_cities_with_districts(self, cities_data: List[Dict]) -> bool:
        """
        çˆ¬å–å…¨éƒ¨åŸå¸‚åˆ†å€è³‡æ–™
        
        Args:
            cities_data: åŸå¸‚è³‡æ–™åˆ—è¡¨
            
        Returns:
            Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±æ•—
        """
        try:
            # åˆå§‹åŒ–æ›´æ–°æ—¥èªŒè³‡æ–™
            self._update_log_data = {}
            
            # è¨ˆç®—æ‰€æœ‰åŸå¸‚çš„ç¸½å€åŸŸæ•¸é‡
            total_districts = sum(len(city['districts']) for city in cities_data)
            current_district = 0  # ç•¶å‰è™•ç†çš„å€åŸŸæ•¸é‡
            
            for city in cities_data:  # éæ­·æ¯å€‹åŸå¸‚
                if self.should_stop:  # å¦‚æœéœ€è¦åœæ­¢
                    break  # çµæŸè¿´åœˆ
                    
                self.create_city_folder(city['name'], city['count'])  # å»ºç«‹åŸå¸‚è³‡æ–™å¤¾
                
                for district in city['districts']:  # éæ­·åŸå¸‚çš„æ¯å€‹å€åŸŸ
                    if self.should_stop:  # å¦‚æœéœ€è¦åœæ­¢
                        break  # çµæŸè¿´åœˆ
                        
                    current_district += 1  # å€åŸŸè¨ˆæ•¸åŠ 1
                    self._update_progress(current_district, total_districts)  # æ›´æ–°é€²åº¦
                    
                    success = self.find_data(  # çˆ¬å–å€åŸŸè³‡æ–™
                        district['url'], 
                        city['name'], 
                        district['name'], 
                        district['count'], 
                        "æ˜¯",
                        city['count']
                    )
                    if not success:  # å¦‚æœçˆ¬å–å¤±æ•—
                        return False  # è¿”å›å¤±æ•—
            
            # å»ºç«‹æ›´æ–°æ—¥èªŒ
            if hasattr(self, '_update_log_data'):
                self.create_update_log(self._update_log_data)
            
            return not self.should_stop  # å¦‚æœæ²’æœ‰åœæ­¢å‰‡è¿”å›æˆåŠŸ
            
        except Exception as e:  # æ•æ‰ç•°å¸¸
            self._update_status(f"çˆ¬å–å…¨éƒ¨åŸå¸‚åˆ†å€è³‡æ–™å¤±æ•—: {str(e)}")  # æ›´æ–°éŒ¯èª¤ç‹€æ…‹
            return False  # è¿”å›å¤±æ•—

    def scrape_single_city_with_districts(self, city_data: Dict) -> bool:
        """
        çˆ¬å–å–®ä¸€åŸå¸‚åˆ†å€è³‡æ–™
        
        Args:
            city_data: åŸå¸‚è³‡æ–™å­—å…¸
            
        Returns:
            Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±æ•—
        """
        try:
            # åˆå§‹åŒ–æ›´æ–°æ—¥èªŒè³‡æ–™
            self._update_log_data = {}
            
            self.create_city_folder(city_data['name'], city_data['count'])  # å»ºç«‹åŸå¸‚è³‡æ–™å¤¾
            total_districts = len(city_data['districts'])  # ç¸½å€åŸŸæ•¸é‡
            
            for i, district in enumerate(city_data['districts']):  # éæ­·æ¯å€‹å€åŸŸ
                if self.should_stop:  # å¦‚æœéœ€è¦åœæ­¢
                    break  # çµæŸè¿´åœˆ
                    
                self._update_progress(i + 1, total_districts)  # æ›´æ–°é€²åº¦
                
                success = self.find_data(  # çˆ¬å–å€åŸŸè³‡æ–™
                    district['url'], 
                    city_data['name'], 
                    district['name'], 
                    district['count'], 
                    "æ˜¯",
                    city_data['count']
                )
                if not success:  # å¦‚æœçˆ¬å–å¤±æ•—
                    return False  # è¿”å›å¤±æ•—
            
            # å»ºç«‹æ›´æ–°æ—¥èªŒ
            if hasattr(self, '_update_log_data'):
                self.create_update_log(self._update_log_data)
            
            return not self.should_stop  # å¦‚æœæ²’æœ‰åœæ­¢å‰‡è¿”å›æˆåŠŸ
            
        except Exception as e:  # æ•æ‰ç•°å¸¸
            self._update_status(f"çˆ¬å–å–®ä¸€åŸå¸‚åˆ†å€è³‡æ–™å¤±æ•—: {str(e)}")  # æ›´æ–°éŒ¯èª¤ç‹€æ…‹
            return False  # è¿”å›å¤±æ•—
    
    def scrape_single_district(self, city_data: Dict, district_name: str) -> bool:
        """
        çˆ¬å–å–®ä¸€å€åŸŸè³‡æ–™
        
        Args:
            city_data: åŸå¸‚è³‡æ–™å­—å…¸
            district_name: å€åŸŸåç¨±
            
        Returns:
            Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±æ•—
        """
        try:
            # åˆå§‹åŒ–æ›´æ–°æ—¥èªŒè³‡æ–™
            self._update_log_data = {}
            
            self.create_city_folder(city_data['name'], city_data['count'])  # å»ºç«‹åŸå¸‚è³‡æ–™å¤¾
            
            # å°‹æ‰¾æŒ‡å®šçš„å€åŸŸ
            target_district = None  # åˆå§‹åŒ–ç›®æ¨™å€åŸŸ
            for district in city_data['districts']:  # éæ­·æ‰€æœ‰å€åŸŸ
                if district['name'] == district_name:  # å¦‚æœæ‰¾åˆ°æŒ‡å®šå€åŸŸ
                    target_district = district  # è¨­å®šç›®æ¨™å€åŸŸ
                    break  # çµæŸæœå°‹
            
            if not target_district:  # å¦‚æœæ²’æœ‰æ‰¾åˆ°æŒ‡å®šå€åŸŸ
                self._update_status(f"æ‰¾ä¸åˆ°å€åŸŸ: {district_name}")  # æ›´æ–°éŒ¯èª¤ç‹€æ…‹
                return False  # è¿”å›å¤±æ•—
            
            self._update_progress(1, 1)  # è¨­å®šé€²åº¦ç‚º100%
            
            success = self.find_data(  # çˆ¬å–å€åŸŸè³‡æ–™
                target_district['url'], 
                city_data['name'], 
                target_district['name'], 
                target_district['count'], 
                "æ˜¯",
                city_data['count']
            )
            
            # å»ºç«‹æ›´æ–°æ—¥èªŒ
            if hasattr(self, '_update_log_data'):
                self.create_update_log(self._update_log_data)
            
            return success  # è¿”å›çˆ¬å–çµæœ
            
        except Exception as e:  # æ•æ‰ç•°å¸¸
            self._update_status(f"çˆ¬å–å–®ä¸€å€åŸŸè³‡æ–™å¤±æ•—: {str(e)}")  # æ›´æ–°éŒ¯èª¤ç‹€æ…‹
            return False  # è¿”å›å¤±æ•—